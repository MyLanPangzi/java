#bin/flume-ng agent --conf conf --conf-file job/replica/hdfs-agent.conf --name hdfs
hdfs.sources = hdfs-source
hdfs.sinks = hdfs-sink
hdfs.channels = hdfs-channel
# Bind the source and sink to the channel
hdfs.sources.hdfs-source.channels = hdfs-channel
hdfs.sinks.hdfs-sink.channel = hdfs-channel
# Describe/configure the source
hdfs.sources.hdfs-source.type = avro
hdfs.sources.hdfs-source.bind = hadoop100
hdfs.sources.hdfs-source.port = 40020

# Describe the sink
hdfs.sinks.hdfs-sink.type = hdfs
hdfs.sinks.hdfs-sink.hdfs.path = hdfs://mycluster/flume/upload/%Y%m%d/%H
#上传文件的前缀
hdfs.sinks.hdfs-sink.hdfs.filePrefix = upload-
#是否按照时间滚动文件夹
hdfs.sinks.hdfs-sink.hdfs.round = true
#多少时间单位创建一个新的文件夹
hdfs.sinks.hdfs-sink.hdfs.roundValue = 1
#重新定义时间单位
hdfs.sinks.hdfs-sink.hdfs.roundUnit = hour
#是否使用本地时间戳
hdfs.sinks.hdfs-sink.hdfs.useLocalTimeStamp = true
#积攒多少个Event才flush到HDFS一次
hdfs.sinks.hdfs-sink.hdfs.batchSize = 10
#设置文件类型，可支持压缩
hdfs.sinks.hdfs-sink.hdfs.fileType = DataStream
#多久生成一个新的文件
hdfs.sinks.hdfs-sink.hdfs.rollInterval = 0
#设置每个文件的滚动大小大概是128M
hdfs.sinks.hdfs-sink.hdfs.rollSize = 134217700
#文件的滚动与Event数量无关
hdfs.sinks.hdfs-sink.hdfs.rollCount = 0

# Use a channel which buffers events in memory
hdfs.channels.hdfs-channel.type = memory
hdfs.channels.hdfs-channel.capacity = 1000
hdfs.channels.hdfs-channel.transactionCapacity = 100

